name: Test

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read
  id-token: write

jobs:
  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v5
      - name: Install uv
        uses: astral-sh/setup-uv@3259c6206f993105e3a61b142c2d97bf4b9ef83d
      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version-file: "pyproject.toml"
      - name: Install dependencies
        run: uv sync --dev
      - name: Lint
        run: uv run ruff check .
      - name: Format
        run: uv run ruff format --diff .
      - name: Check types
        run: uv run mypy --install-types --non-interactive .
      - name: Pyright
        # for catching method override errors with different parameter names
        # reportIncompatibleMethodOverride, not covered by mypy
        run: uv run pyright

  unit-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v5
      - name: Install uv
        uses: astral-sh/setup-uv@3259c6206f993105e3a61b142c2d97bf4b9ef83d
      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version-file: "pyproject.toml"
      - name: Install dependencies
        run: uv sync --dev
      - name: Test
        run: uv run pytest -m 'not kernel and not studio and not openai'

  kernel-openai-inference-test:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write
      packages: read
      models: read
    steps:
      - uses: actions/checkout@v4
      - name: Install uv
        uses: astral-sh/setup-uv@7edac99f961f18b581bbd960d59d049f04c0002f
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version-file: "pyproject.toml"
      - name: Install dependencies
        run: uv sync --dev
      - name: Run Pharia Kernel against the GitHub models inference backend
        run: |
          podman login ghcr.io -u ${{ github.actor }} -p ${{ secrets.GITHUB_TOKEN }}
          podman pull ghcr.io/aleph-alpha/pharia-kernel/pharia-kernel:latest
          podman tag ghcr.io/aleph-alpha/pharia-kernel/pharia-kernel:latest pharia-kernel
          (podman run -p 8081:8081 -e OPENAI_INFERENCE__URL=https://models.github.ai/inference -e OPENAI_INFERENCE__TOKEN=${{ secrets.GITHUB_TOKEN }} pharia-kernel | cat) &
      - name: Test
        run: uv run pytest -m openai
        env:
          PHARIA_KERNEL_ADDRESS: http://127.0.0.1:8081

  kernel-and-studio-test:
    runs-on: cpu-runner-8c-32gb-01
    permissions:
      contents: read
      id-token: write
      packages: read
    env:
      PHARIA_AI_TOKEN: ${{ secrets.PHARIA_AI_TOKEN }}
    steps:
      - uses: actions/checkout@v5
      - name: Install uv
        uses: astral-sh/setup-uv@3259c6206f993105e3a61b142c2d97bf4b9ef83d
      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version-file: "pyproject.toml"
      - name: Install dependencies
        run: uv sync --dev
      - name: Run Pharia Kernel
        run: sh -x -e ./scripts/run_kernel.sh ${{ github.actor }} ${{ secrets.GITHUB_TOKEN }} stage.product.pharia.com
      - name: Run kernel and studio tests
        run: uv run pytest -m '(kernel or studio) and not openai'
        env:
          PHARIA_KERNEL_ADDRESS: http://127.0.0.1:8081
          PHARIA_STUDIO_ADDRESS: https://pharia-studio-api.stage.product.pharia.com
          DOCUMENT_INDEX_ADDRESS: https://document-index.stage.product.pharia.com
      - name: Run example tests
        run: uv run pytest examples
        env:
          PHARIA_KERNEL_ADDRESS: http://127.0.0.1:8081
          PHARIA_STUDIO_ADDRESS: https://pharia-studio-api.stage.product.pharia.com

  integration-test:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        # Using cpu-runner-8c-32gb-01 to run integration tests against p-stage
        os: [ubuntu-latest, windows-latest, macos-latest, cpu-runner-8c-32gb-01]
    permissions:
      contents: read
      id-token: write
      packages: write
    env:
      PHARIA_AI_TOKEN: ${{ secrets.PHARIA_AI_TOKEN }}
    steps:
      - uses: actions/checkout@v5
      - name: Install uv
        uses: astral-sh/setup-uv@3259c6206f993105e3a61b142c2d97bf4b9ef83d
      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version-file: "pyproject.toml"
      - name: Install dependencies
        run: uv sync --dev
      - name: Test skill building
        run: |
          uv run pharia-skill build tests.skills.haiku --no-interactive --unstable
          uv run pharia-skill build tests.skills.search --no-interactive --unstable
          uv run pharia-skill build tests.skills.language --no-interactive --unstable
          uv run pharia-skill build tests.skills.failing --no-interactive --unstable
          uv run pharia-skill build tests.skills.bad_csi_input --no-interactive --unstable
          uv run pharia-skill build tests.skills.streaming_haiku_chat --no-interactive --skill-type message-stream-skill --unstable
          uv run pharia-skill build tests.skills.streaming_haiku_completion --no-interactive --skill-type message-stream-skill --unstable
          uv run pharia-skill build tests.skills.streaming_reasoning --no-interactive --skill-type message-stream-skill --unstable
      - name: Create .env file for skill publishing
        run: |
          echo "SKILL_REGISTRY_USER=${{ github.actor }}" > .env
          echo "SKILL_REGISTRY_TOKEN=${{ secrets.GITHUB_TOKEN }}" >> .env
          echo "SKILL_REGISTRY=ghcr.io" >> .env
          echo "SKILL_REPOSITORY=aleph-alpha/pharia-kernel-sdk-py/skills" >> .env
      - name: Test skill publishing
        run: uv run pharia-skill publish haiku
      - name: Test skill execution on p-stage
        if: ${{ matrix.os == 'cpu-runner-8c-32gb-01' }}
        run: |
          sh -x -e ./scripts/run_kernel.sh ${{ github.actor }} ${{ secrets.GITHUB_TOKEN }} stage.product.pharia.com
          uv run sh -x -e ./scripts/run_skill.sh haiku $PHARIA_AI_TOKEN
          uv run sh -x -e ./scripts/run_skill.sh search $PHARIA_AI_TOKEN
          uv run sh -x -e ./scripts/run_skill.sh language $PHARIA_AI_TOKEN
          uv run sh -x -e ./scripts/run_streaming_skill.sh streaming_haiku_chat $PHARIA_AI_TOKEN
          uv run sh -x -e ./scripts/run_streaming_skill.sh streaming_haiku_completion $PHARIA_AI_TOKEN
          uv run sh -x -e ./scripts/run_failing_skill.sh $PHARIA_AI_TOKEN
          uv run sh -x -e ./scripts/run_bad_csi_input_skill.sh $PHARIA_AI_TOKEN
          uv run sh -x -e ./scripts/run_streaming_skill_reasoning.sh streaming_reasoning $PHARIA_AI_TOKEN
      - name: Test skill metadata on p-stage
        if: ${{ matrix.os == 'cpu-runner-8c-32gb-01' }}
        run: |
          uv run sh -x -e ./scripts/metadata_skill.sh haiku $PHARIA_AI_TOKEN
